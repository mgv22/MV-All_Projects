{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3d0a0c6a7b9426f865512f5d52f16d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c19c2f1d681d40bd91e332db2341c462",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61a4fc5a0b04414381b6367c182c6ef3",
              "IPY_MODEL_43550385ac424ca0a1e188bb6498ba84",
              "IPY_MODEL_f17d1d0651064481ba0b019401d8f500"
            ]
          }
        },
        "c19c2f1d681d40bd91e332db2341c462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61a4fc5a0b04414381b6367c182c6ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_89ecd199ec4b4c18890d4e6ba876898e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_432c0f9826a94b389f90a6ca052b47f6"
          }
        },
        "43550385ac424ca0a1e188bb6498ba84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c06c9bd13fb4de880101a503fe32aae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 25001,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25001,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50c275b885004a2ba772480103db68b4"
          }
        },
        "f17d1d0651064481ba0b019401d8f500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2372d475074744fb8854aa0097e974d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25001/25001 [01:03&lt;00:00, 388.72it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b38968cd21542ba94e764066f682166"
          }
        },
        "89ecd199ec4b4c18890d4e6ba876898e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "432c0f9826a94b389f90a6ca052b47f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c06c9bd13fb4de880101a503fe32aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50c275b885004a2ba772480103db68b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2372d475074744fb8854aa0097e974d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b38968cd21542ba94e764066f682166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baxlvd1lgFE4",
        "outputId": "caf0665b-4add-4dfc-c808-4cffe57282d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gme4bZkKUcgq",
        "outputId": "a6c8432b-5252-4c3e-f1e6-bc3dfb08a141"
      },
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEHMO3H0gOlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67cf60cb-4f83-48d6-8e99-639c1f9ba43a"
      },
      "source": [
        "import sklearn\n",
        "import seaborn as sns\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "import datetime\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from scipy import stats\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import silhouette_samples\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "from sklearn.linear_model import RidgeCV, ElasticNetCV, LassoCV\n",
        "from sklearn.decomposition import PCA #Principal Component Analysis\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler #transforms categorical into numbers\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import mean_squared_error, make_scorer, f1_score, confusion_matrix\n",
        "import xgboost\n",
        "from sklearn.cluster import KMeans\n",
        "import zipfile\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import os, cv2, re, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras import layers, models, optimizers\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOF6infBQuc0",
        "outputId": "396a769b-3126-4df1-c6fb-fdfe3ab2c67e"
      },
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVW-s-ICRFlG"
      },
      "source": [
        "LR = 1e-3\n",
        "MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '2conv-basic')\n",
        "RANDOM_SEED = 42\n",
        "IMG_WIDTH = 150\n",
        "IMG_HEIGHT = 150\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "IMG_SHAPE = [IMG_WIDTH, IMG_HEIGHT]\n",
        "IMG_LENGTH = IMG_WIDTH * IMG_HEIGHT\n",
        "\n",
        "def get_model_baseline():\n",
        "  convnet = input_data(shape=[None, IMG_WIDTH, IMG_HEIGHT, 3], name='input')\n",
        "\n",
        "  convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "  convnet = dropout(convnet, 0.8)\n",
        "\n",
        "  convnet = fully_connected(convnet, 2, activation='softmax')\n",
        "  convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
        "\n",
        "  return tflearn.DNN(convnet, tensorboard_dir='log')\n",
        "\n",
        "def reset_graph(seed= RANDOM_SEED):\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssxa6AuEROZk"
      },
      "source": [
        "def get_model_v2():\n",
        "  convnet = input_data(shape=[None, IMG_WIDTH, IMG_HEIGHT, 3], name='input')\n",
        "\n",
        "  convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "  convnet = dropout(convnet, 0.8)\n",
        "\n",
        "  convnet = fully_connected(convnet, 2, activation='softmax')\n",
        "  convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
        "\n",
        "  return tflearn.DNN(convnet, tensorboard_dir='log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xINfxHBSp7L"
      },
      "source": [
        "def label_img(img_name):\n",
        "  if 'cat' in img_name: return [1, 0]\n",
        "  elif 'dog' in img_name: return [0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "f3d0a0c6a7b9426f865512f5d52f16d1",
            "c19c2f1d681d40bd91e332db2341c462",
            "61a4fc5a0b04414381b6367c182c6ef3",
            "43550385ac424ca0a1e188bb6498ba84",
            "f17d1d0651064481ba0b019401d8f500",
            "89ecd199ec4b4c18890d4e6ba876898e",
            "432c0f9826a94b389f90a6ca052b47f6",
            "2c06c9bd13fb4de880101a503fe32aae",
            "50c275b885004a2ba772480103db68b4",
            "2372d475074744fb8854aa0097e974d2",
            "5b38968cd21542ba94e764066f682166"
          ]
        },
        "id": "y1t1Z-iFSrS7",
        "outputId": "efe501f9-e8ad-40d6-bd23-5b1b870c9268"
      },
      "source": [
        "training_data = []\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/train.zip', 'r') as z:\n",
        "  for fn in tqdm(z.namelist()):\n",
        "    if not os.path.isdir(fn) and fn.endswith(\"jpg\"):\n",
        "      label = label_img(fn)\n",
        "\n",
        "      img_str = z.read(fn)\n",
        "\n",
        "      nparr = np.frombuffer(img_str, np.uint8)\n",
        "\n",
        "      img_np = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "      img = cv2.resize(img_np, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "      training_data.append([ np.array(img), np.array(label)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3d0a0c6a7b9426f865512f5d52f16d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/25001 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "lKy85Bp4UJXN",
        "outputId": "453fbf3f-13d2-4395-eb6c-846918ecdf08"
      },
      "source": [
        "train_size = int(len(training_data) * .8)\n",
        "train_size\n",
        "\n",
        "train = training_data[-train_size:]\n",
        "display('Train Size: {}'.format(len(train)))\n",
        "\n",
        "test = training_data[:-train_size]\n",
        "display('Test Size: {}'.format(len(test)))\n",
        "\n",
        "X_train = np.array([i[0] for i in train]).reshape(-1,IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS)\n",
        "y_train = np.array([i[1] for i in train])\n",
        "\n",
        "X_test = np.array([i[0] for i in test]).reshape(-1,IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS)\n",
        "y_test = np.array([i[1] for i in test])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Train Size: 20000'"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Test Size: 5000'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln4OnhVxRajd",
        "outputId": "02b22092-8d6c-48ae-a5a8-546a640d51f5"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "model_baseline = get_model_baseline()\n",
        "\n",
        "start_time = time.clock()\n",
        "\n",
        "model_baseline.fit({'input': X_train}, {'targets': y_train}, n_epoch=3, validation_set=({'input': X_test}, {'targets': y_test}),\n",
        "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
        "\n",
        "end_time = time.clock()\n",
        "\n",
        "runtime = end_time - start_time  # seconds of wall-clock time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 938  | total loss: \u001b[1m\u001b[32m8.61262\u001b[0m\u001b[0m | time: 11.198s\n",
            "| Adam | epoch: 003 | loss: 8.61262 - acc: 0.6260 -- iter: 19968/20000\n",
            "Training Step: 939  | total loss: \u001b[1m\u001b[32m8.39896\u001b[0m\u001b[0m | time: 12.439s\n",
            "| Adam | epoch: 003 | loss: 8.39896 - acc: 0.6352 | val_loss: 23.02585 - val_acc: 0.0000 -- iter: 20000/20000\n",
            "--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjaZWJCOVQ5j",
        "outputId": "71763294-4831-4648-d95d-199f73718133"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "model_v2 = get_model_v2()\n",
        "\n",
        "start_time = time.clock()\n",
        "\n",
        "model_v2.fit({'input': X_train}, {'targets': y_train}, n_epoch=3, validation_set=({'input': X_test}, {'targets': y_test}),\n",
        "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
        "\n",
        "end_time = time.clock()\n",
        "\n",
        "runtime = end_time - start_time  # seconds of wall-clock time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 751  | total loss: \u001b[1m\u001b[32m0.46702\u001b[0m\u001b[0m | time: 4.615s\n",
            "\u001b[2K\r| Adam | epoch: 003 | loss: 0.46702 - acc: 0.7723 -- iter: 08000/20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Js2KoUVcSf"
      },
      "source": [
        "training_data2 = []\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/train.zip', 'r') as z:\n",
        "  for fn in tqdm(z.namelist()):\n",
        "    if not os.path.isdir(fn) and fn.endswith(\"jpg\"):\n",
        "      label = label_img(fn)\n",
        "\n",
        "      img_str = z.read(fn)\n",
        "\n",
        "      nparr = np.frombuffer(img_str, np.uint8)\n",
        "\n",
        "      img_np = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)\n",
        "      img = cv2.resize(img_np, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "      training_data2.append([ np.array(img), np.array(label)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yya97GIEV0vK"
      },
      "source": [
        "train_size2 = int(len(training_data2) * .8)\n",
        "train_size2\n",
        "\n",
        "train2 = training_data2[-train_size2:]\n",
        "display('Train Size: {}'.format(len(train2)))\n",
        "\n",
        "test2 = training_data2[:-train_size2]\n",
        "display('Test Size: {}'.format(len(test2)))\n",
        "\n",
        "X_train2 = np.array([i[0] for i in train2]).reshape(-1,IMG_WIDTH, IMG_HEIGHT, 1)\n",
        "y_train2 = np.array([i[1] for i in train2])\n",
        "\n",
        "X_test2 = np.array([i[0] for i in test2]).reshape(-1,IMG_WIDTH, IMG_HEIGHT, 1)\n",
        "y_test2 = np.array([i[1] for i in test2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urtvu7VhWXcJ"
      },
      "source": [
        "training_data2[0][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-YFHonUYBGU"
      },
      "source": [
        "def get_model_baseline2():\n",
        "  convnet = input_data(shape=[None, IMG_WIDTH, IMG_HEIGHT, 1], name='input')\n",
        "\n",
        "  convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "  convnet = dropout(convnet, 0.8)\n",
        "\n",
        "  convnet = fully_connected(convnet, 2, activation='softmax')\n",
        "  convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
        "\n",
        "  return tflearn.DNN(convnet, tensorboard_dir='log')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N7n9iYAYRHE"
      },
      "source": [
        "def get_model_v2_2():\n",
        "  convnet = input_data(shape=[None, IMG_WIDTH, IMG_HEIGHT, 1], name='input')\n",
        "\n",
        "  convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "  convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "  convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "  convnet = dropout(convnet, 0.8)\n",
        "\n",
        "  convnet = fully_connected(convnet, 2, activation='softmax')\n",
        "  convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
        "\n",
        "  return tflearn.DNN(convnet, tensorboard_dir='log')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW3A94XuWAjY"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "model_baseline2 = get_model_baseline2()\n",
        "\n",
        "start_time = time.clock()\n",
        "\n",
        "model_baseline2.fit({'input': X_train2}, {'targets': y_train2}, n_epoch=3, validation_set=({'input': X_test2}, {'targets': y_test2}),\n",
        "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
        "\n",
        "end_time = time.clock()\n",
        "\n",
        "runtime = end_time - start_time  # seconds of wall-clock time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ysqDa_cWJ1q"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "model_v2_2 = get_model_v2_2()\n",
        "\n",
        "start_time = time.clock()\n",
        "\n",
        "model_v2_2.fit({'input': X_train2}, {'targets': y_train2}, n_epoch=3, validation_set=({'input': X_test2}, {'targets': y_test2}),\n",
        "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
        "\n",
        "end_time = time.clock()\n",
        "\n",
        "runtime = end_time - start_time  # seconds of wall-clock time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIFeRNN8YvQB"
      },
      "source": [
        "test_data = []\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/test.zip', 'r') as z:\n",
        "  for fn in tqdm(z.namelist()):\n",
        "    if not os.path.isdir(fn) and fn.endswith(\"jpg\"):\n",
        "      label = label_img(fn)\n",
        "\n",
        "      img_str = z.read(fn)\n",
        "\n",
        "      nparr = np.frombuffer(img_str, np.uint8)\n",
        "\n",
        "      img_np = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "      img = cv2.resize(img_np, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "      test_data.append([ np.array(img), np.array(label)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVm_HCuIZKSR"
      },
      "source": [
        "test_data2 = []\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/test.zip', 'r') as z:\n",
        "  for fn in tqdm(z.namelist()):\n",
        "    if not os.path.isdir(fn) and fn.endswith(\"jpg\"):\n",
        "      label = label_img(fn)\n",
        "\n",
        "      img_str = z.read(fn)\n",
        "\n",
        "      nparr = np.frombuffer(img_str, np.uint8)\n",
        "\n",
        "      img_np = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)\n",
        "      img = cv2.resize(img_np, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "      test_data2.append(np.array(img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0enJyrGmafML"
      },
      "source": [
        "model_baseline2.predict(test_data2.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4qevJneZB69"
      },
      "source": [
        "for data, label in test_data2:\n",
        "  print(data)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVc4tN7ndyB2"
      },
      "source": [
        "!unzip /content/drive/MyDrive/train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_OOcXyZd1ie"
      },
      "source": [
        "!unzip /content/drive/MyDrive/test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYDM9QwTGCFn"
      },
      "source": [
        "TRAIN_DIR = 'train/'\n",
        "TEST_DIR = 'test/'\n",
        "train_dogs = ['./train/{}'.format(i) for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
        "train_cats = ['./train/{}'.format(i) for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
        "test_images_dogs_cats = ['./test/{}'.format(i) for i in os.listdir(TEST_DIR)]\n",
        "len(train_dogs), len(train_cats), len(test_images_dogs_cats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3KvtnaeGGUs"
      },
      "source": [
        "def atoi(text):\n",
        "    return int(text) if text.isdigit() else text\n",
        "\n",
        "def natural_keys(text):\n",
        "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
        "\n",
        "train_dogs.sort(key=natural_keys)\n",
        "train_cats.sort(key=natural_keys)\n",
        "train_images_dogs_cats = train_dogs[0:1300] + train_cats[0:1300]\n",
        "\n",
        "test_images_dogs_cats.sort(key=natural_keys)\n",
        "len(train_images_dogs_cats), len(test_images_dogs_cats)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzU7yyshGTpJ"
      },
      "source": [
        "img_width = 150\n",
        "img_height = 150\n",
        "def prepare_data(list_of_images):\n",
        "    \"\"\"\n",
        "    Returns two arrays:\n",
        "        x is an array of resized images\n",
        "        y is an array of labels\n",
        "    \"\"\"\n",
        "    x = [] # images as arrays\n",
        "    y = [] # labels\n",
        "\n",
        "    for image in list_of_images:\n",
        "        x.append(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))\n",
        "\n",
        "    for i in list_of_images:\n",
        "        if 'dog' in i:\n",
        "            y.append(1)\n",
        "        elif 'cat' in i:\n",
        "            y.append(0)\n",
        "    return x, y\n",
        "\n",
        "X, Y = prepare_data(train_images_dogs_cats)\n",
        "XT, YT = prepare_data(test_images_dogs_cats)\n",
        "print(K.image_data_format())\n",
        "# Since K.image_data_format() is channel_last,\n",
        "# input_shape to the first keras layer will be (img_width, img_height, 3).\n",
        "# '3' since it is a color image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXciPcC2yn3H"
      },
      "source": [
        "CD_train= 'train'\n",
        "CD_test= 'test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mtzcdNfGaB-"
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=0.2, random_state=1)\n",
        "X_test = XT\n",
        "nb_train_samples = len(X_train)\n",
        "nb_validation_samples = len(X_val)\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWGdGYt6G0Dn"
      },
      "source": [
        "X_train[0].shape, X_val[0].shape, X_test[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aSA2qtuE4Wo"
      },
      "source": [
        "def gen_image_label(directory):\n",
        "    ''' A generator that yields (label, id, jpg_filename) tuple.'''\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for f in files:\n",
        "            _, ext = os.path.splitext(f)\n",
        "            if ext != '.jpg':\n",
        "                continue\n",
        "            basename = os.path.basename(f)\n",
        "            splits = basename.split('.')\n",
        "            if len(splits) == 3:\n",
        "                label, id_, ext = splits\n",
        "            else:\n",
        "                label = None\n",
        "                id_, ext = splits\n",
        "            fullname = os.path.join(root, f)\n",
        "            yield label, int(id_), fullname"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX9pQnJnFcBn"
      },
      "source": [
        "# Wrap testing data into pandas' DataFrame.\n",
        "lst = list(gen_image_label(CD_test))\n",
        "CD_test_df = pd.DataFrame(lst, columns=['label', 'id', 'filename'])\n",
        "CD_test_df = CD_test_df.sort_values(by=['label', 'id'])\n",
        "CD_test_df['label_code'] = CD_test_df.label.map({'cat':0, 'dog':1})\n",
        "\n",
        "CD_test_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43DyC2MllIht"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow(np.array(X_train), Y_train, batch_size=batch_size)\n",
        "validation_generator = val_datagen.flow(np.array(X_val), Y_val, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2R2aGnL4Cxg"
      },
      "source": [
        "model1A = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
        "                        input_shape=[150, 150, 3]),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model1A.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMcn5L6UlSDm"
      },
      "source": [
        "%time\n",
        "history = model1A.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8lnJXI07vQ9"
      },
      "source": [
        "y_pred_1A= model1A.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiUarBti4IRr"
      },
      "source": [
        "#removed dropout\n",
        "\n",
        "model2A = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
        "                        input_shape=[150, 150, 3]),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    #keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    #keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    #keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model2A.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdEHKB5yN0xo"
      },
      "source": [
        "%time\n",
        "history = model2A.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HReBsIHr7xLt"
      },
      "source": [
        "y_pred_2A= model2A.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rklLYrlM4cPE"
      },
      "source": [
        "#B series models have more nodes and layers\n",
        "\n",
        "model1B = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
        "                        input_shape=[150, 150, 3]),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model1B.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL5KaTdNOMVg"
      },
      "source": [
        "%time\n",
        "history = model1B.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epQgit5u7o9z"
      },
      "source": [
        "%time history = model1B.fit(np.array(X_train), np.array(Y_train), epochs=10,\\\n",
        "                            validation_data=(np.array(X_val), np.array(Y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qym5u1B-70Kp"
      },
      "source": [
        "y_pred_1B= model1B.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eZGPuoa4gbU"
      },
      "source": [
        "#removed dropout\n",
        "#Cut filters for Conv Layers in half\n",
        "\n",
        "model2B = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
        "                        input_shape=[150, 150, 3]),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model2B.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfa8mTKL7q64"
      },
      "source": [
        "%time history = model2B.fit(np.array(X_train), np.array(Y_train), epochs=10,\\\n",
        "                            validation_data=(np.array(X_val), np.array(Y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aSz-7-m75HB"
      },
      "source": [
        "y_pred_2B= model2B.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
